{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the data by implementing some standard measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import re\n",
    "import glob\n",
    "# Assigning variables for using them.\n",
    "# This is done because it helps in changing variable value and you can test with multiple hyperparameters.\n",
    "\n",
    "#Explananion of  variable\n",
    "DATA_AUG_POS_SHIFT_MIN = -2                      # Objects in this dataset are not be centered in the frame.  \n",
    "DATA_AUG_POS_SHIFT_MAX = 2                       # We artificially creating shifted versions of fickr dataset\n",
    "DATA_AUG_SCALES = [0.9, 1.1]                    \n",
    "DATA_AUG_ROT_MIN = -15                           # Image rotation \n",
    "DATA_AUG_ROT_MAX = 15                            \n",
    "CNN_IN_WIDTH = 64                                # Width of the image\n",
    "CNN_IN_HEIGHT = 32                              # Height of the image\n",
    "TRAIN_DIR = 'flickr_logos_27_dataset'            # direorty of the dataset\n",
    "TRAIN_IMAGE_DIR = os.path.join(TRAIN_DIR, 'flickr_logos_27_dataset_images')\n",
    "CROPPED_AUG_IMAGE_DIR = os.path.join(\n",
    "    TRAIN_DIR, 'flickr_logos_27_dataset_cropped_augmented_images')\n",
    "ANNOT_FILE = 'flickr_logos_27_dataset_training_set_annotation.txt' \n",
    "NONE_IMAGE_DIR = os.path.join(TRAIN_DIR, 'SUN397') \n",
    "NUM_OF_NONE_IMAGES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parsing given anotation file in the dataset\n",
    "def parse_annot(annot):\n",
    "    fn = annot[0].decode('utf-8')                 # Filename \n",
    "    class_name = annot[1].decode('utf-8')         # Class name\n",
    "    train_subset_class = annot[2].decode('utf-8') # subset class\n",
    "    return fn, class_name, train_subset_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_wid_hgt(x1, y1, x2, y2):\n",
    "    cx = x1 + (x2 - x1) // 2\n",
    "    cy = y1 + (y2 - y1) // 2\n",
    "    wid = (x2 - x1)\n",
    "    hgt = (y2 - y1)\n",
    "    return cx, cy, wid, hgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rect_coord(annot_part):\n",
    "    return list(map(int, annot_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parsing the cordinate points in the file \n",
    "def get_rect(annot):\n",
    "    rect = defaultdict(int)                   # int Dictionary\n",
    "    x1, y1, x2, y2 = rect_coord(annot[3:])    # saving cordinates in variable s\n",
    "    cx, cy, wid, hgt = center_wid_hgt(x1, y1, x2, y2)    \n",
    "    rect['x1'] = x1\n",
    "    rect['y1'] = y1\n",
    "    rect['x2'] = x2\n",
    "    rect['y2'] = y2\n",
    "    rect['cx'] = cx\n",
    "    rect['cy'] = cy\n",
    "    rect['wid'] = wid\n",
    "    rect['hgt'] = hgt\n",
    "    return rect                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sacling images\n",
    "def aug_scale(annot, im):\n",
    "    aug_scale_ims = []  \n",
    "    aug_scale_suffixes = []\n",
    "\n",
    "    rect = get_rect(annot)\n",
    "    for s in DATA_AUG_SCALES:\n",
    "        w = int(rect['wid'] * s)\n",
    "        h = int(rect['hgt'] * s)\n",
    "        cropped_im = im.crop((rect['cx'] - w // 2, rect['cy'] - h // 2,\n",
    "                              rect['cx'] + w // 2, rect['cy'] + h // 2))\n",
    "        resized_im = cropped_im.resize((CNN_IN_WIDTH, CNN_IN_HEIGHT))\n",
    "        aug_scale_ims.append(resized_im)\n",
    "        aug_scale_suffixes.append('s' + str(s))\n",
    "        cropped_im.close()\n",
    "\n",
    "    return aug_scale_ims, aug_scale_suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shifting centre \n",
    "def aug_pos(annot, im):\n",
    "    aug_pos_ims = []\n",
    "    aug_pos_suffixes = []\n",
    "\n",
    "    rect = get_rect(annot)\n",
    "    for sx, sy in product(\n",
    "            range(DATA_AUG_POS_SHIFT_MIN, DATA_AUG_POS_SHIFT_MAX),\n",
    "            range(DATA_AUG_POS_SHIFT_MIN, DATA_AUG_POS_SHIFT_MAX)):\n",
    "        cx = rect['cx'] + sx\n",
    "        cy = rect['cy'] + sy\n",
    "        cropped_im = im.crop((cx - rect['wid'] // 2, cy - rect['hgt'] // 2,\n",
    "                              cx + rect['wid'] // 2, cy + rect['hgt'] // 2))\n",
    "        resized_im = cropped_im.resize((CNN_IN_WIDTH, CNN_IN_HEIGHT))\n",
    "        aug_pos_ims.append(resized_im)\n",
    "        aug_pos_suffixes.append('p' + str(sx) + str(sy))\n",
    "        cropped_im.close()\n",
    "    return aug_pos_ims, aug_pos_suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for image rotation \n",
    "def aug_rot(annot, im):\n",
    "    aug_rot_ims = []\n",
    "    aug_rot_suffixes = [] \n",
    "\n",
    "    rect = get_rect(annot)\n",
    "    for r in range(DATA_AUG_ROT_MIN, DATA_AUG_ROT_MAX):\n",
    "        rotated_im = im.rotate(r)\n",
    "        cropped_im = rotated_im.crop(\n",
    "            (rect['cx'] - rect['wid'] // 2, rect['cy'] - rect['hgt'] // 2,\n",
    "             rect['cx'] + rect['wid'] // 2, rect['cy'] + rect['hgt'] // 2))\n",
    "        resized_im = cropped_im.resize((CNN_IN_WIDTH, CNN_IN_HEIGHT))\n",
    "        aug_rot_ims.append(resized_im)\n",
    "        aug_rot_suffixes.append('r' + str(r))\n",
    "        rotated_im.close()\n",
    "        cropped_im.close()\n",
    "\n",
    "    return aug_rot_ims, aug_rot_suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# croping images for our CNN;\n",
    "# Images will have height X weight X depth = 64*32*3 \n",
    "def crop_logos(annot, im):\n",
    "    x1, y1, x2, y2 = rect_coord(annot[3:])\n",
    "    cropped_im = im.crop((x1, y1, x2, y2))\n",
    "    cropped_im = cropped_im.resize((CNN_IN_WIDTH, CNN_IN_HEIGHT))\n",
    "    cropped_suffix = 'p00'\n",
    "    return [cropped_im], [cropped_suffix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_skip(annot_part):\n",
    "    x1, y1, x2, y2 = rect_coord(annot_part)\n",
    "    _, _, wid, hgt = center_wid_hgt(x1, y1, x2, y2)\n",
    "    if wid <= 0 or hgt <= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving images into train and test sets according to the class name\n",
    "def save_im(annot, cnt, *args):\n",
    "    fn, class_name, train_subset_class = parse_annot(annot)\n",
    "    dst_dir = os.path.join(CROPPED_AUG_IMAGE_DIR, class_name)\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    for i, arg in enumerate(args):\n",
    "        for im, suffix in zip(arg[0], arg[1]):\n",
    "            save_fn = '_'.join([\n",
    "                fn.split('.')[0], class_name, train_subset_class, str(cnt),\n",
    "                suffix\n",
    "            ]) + os.path.splitext(fn)[1]\n",
    "            im.save(os.path.join(dst_dir, save_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# closing the open image\n",
    "def close_im(*args):\n",
    "    for ims in args:\n",
    "        for im in ims:\n",
    "            im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for cropping and augmentation\n",
    "def crop_and_aug(annot_train):\n",
    "    cnt_per_file = defaultdict(int)\n",
    "    for annot in annot_train:\n",
    "        # for generating a file name\n",
    "        fn, _, _ = parse_annot(annot)\n",
    "        cnt_per_file[fn] += 1\n",
    "\n",
    "        # skip if width or height equal zero\n",
    "        if is_skip(annot[3:]):\n",
    "            print('Skip: ', fn)\n",
    "            continue\n",
    "\n",
    "        # open an image\n",
    "        im = Image.open(os.path.join(TRAIN_IMAGE_DIR, fn))\n",
    "\n",
    "        # normal cropping\n",
    "        cropped_ims, cropped_suffixes = crop_logos(annot, im)\n",
    "\n",
    "        # augment by shifting a center\n",
    "        shifted_ims, shifted_suffixes = aug_pos(annot, im)\n",
    "\n",
    "        # augment by scaling\n",
    "        scaled_ims, scaled_suffixes = aug_scale(annot, im)\n",
    "\n",
    "        # augment by rotation\n",
    "        rotated_ims, rotated_suffixes = aug_rot(annot, im)\n",
    "\n",
    "        # save images\n",
    "        save_im(annot, cnt_per_file[fn], [cropped_ims, cropped_suffixes],\n",
    "                [shifted_ims, shifted_suffixes], [scaled_ims, scaled_suffixes],\n",
    "                [rotated_ims, rotated_suffixes])\n",
    "\n",
    "        # close image file\n",
    "        close_im([im], cropped_ims, shifted_ims, scaled_ims, rotated_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_aug(annot_train, with_none=False):\n",
    "    # root directory to save processed images\n",
    "    if not os.path.exists(CROPPED_AUG_IMAGE_DIR):\n",
    "        os.makedirs(CROPPED_AUG_IMAGE_DIR)\n",
    "\n",
    "    # crop images and apply augmentation\n",
    "    crop_and_aug(annot_train)\n",
    "\n",
    "    # print results\n",
    "    org_imgs = [img for img in os.listdir(TRAIN_IMAGE_DIR)]\n",
    "    crop_and_aug_imgs = [\n",
    "        fname\n",
    "        for root, dirs, files in os.walk(CROPPED_AUG_IMAGE_DIR)\n",
    "        for fname in glob.glob(os.path.join(root, '*.jpg'))\n",
    "    ]\n",
    "    print('original: %d' % (len(org_imgs)))\n",
    "    print('cropped: %d' % (len(crop_and_aug_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_train_test_split():\n",
    "    class_names = [cls for cls in os.listdir(CROPPED_AUG_IMAGE_DIR)]\n",
    "    for class_name in class_names:\n",
    "        if os.path.exists(\n",
    "                os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'train')):\n",
    "            continue\n",
    "        if os.path.exists(\n",
    "                os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'test')):\n",
    "            continue\n",
    "\n",
    "        imgs = [\n",
    "            img\n",
    "            for img in os.listdir(\n",
    "                os.path.join(CROPPED_AUG_IMAGE_DIR, class_name))\n",
    "        ]\n",
    "        # train=0.75, test=0.25\n",
    "        train_imgs, test_imgs = train_test_split(imgs)\n",
    "        # move images to train or test directory\n",
    "        os.makedirs(os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'train'))\n",
    "        os.makedirs(os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'test'))\n",
    "        for img in train_imgs:\n",
    "            dst = os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'train')\n",
    "            src = os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, img)\n",
    "            shutil.move(src, dst)\n",
    "        for img in test_imgs:\n",
    "            dst = os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'test')\n",
    "            src = os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, img)\n",
    "            shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_annotation: 4536, 7 \n",
      "Skip:  2662264721.jpg\n",
      "Skip:  2662264721.jpg\n",
      "Skip:  2662264721.jpg\n",
      "Skip:  2662264721.jpg\n",
      "Skip:  2662264721.jpg\n",
      "original: 1079\n",
      "cropped: 217488\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    annot_train = np.loadtxt(os.path.join(TRAIN_DIR, ANNOT_FILE), dtype='a')\n",
    "    print('train_annotation: %d, %d ' % (annot_train.shape))\n",
    "\n",
    "    # cropping and data augmentation\n",
    "    crop_aug(annot_train)\n",
    "\n",
    "    # train_test_split\n",
    "    do_train_test_split()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
