{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spliting data into train, test, validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "import re\n",
    "import common\n",
    "\n",
    "# Image dimensions\n",
    "CNN_IN_WIDTH = 64 \n",
    "CNN_IN_HEIGHT = 32\n",
    "# image channels\n",
    "CNN_IN_CH = 3\n",
    "# pixel depth\n",
    "PIXEL_DEPTH = 255.0\n",
    "TRAIN_DIR = 'flickr_logos_27_dataset'\n",
    "CROPPED_AUG_IMAGE_DIR = os.path.join(\n",
    "    TRAIN_DIR, 'flickr_logos_27_dataset_cropped_augmented_images')\n",
    "PICKLE_FILENAME = 'deep_logo.pickle'\n",
    "\n",
    "# I'm using this va;ue because I have dual core laptop for traning. Increasing my dataset for traning is not possible for me\n",
    "# The original datastet after image augmentation is 2.4GB  \n",
    "\n",
    "TRAIN_SIZE = 50  \n",
    "VALID_SIZE = 5\n",
    "TEST_SIZE = 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading  images \n",
    "def load_logo(data_dir):\n",
    "    image_files = os.listdir(data_dir)\n",
    "    # creating numpy array of images.\n",
    "    dataset = np.ndarray(\n",
    "        shape=(len(image_files), CNN_IN_HEIGHT, CNN_IN_WIDTH, CNN_IN_CH),\n",
    "        dtype=np.float32)\n",
    "    print(data_dir)\n",
    "    num_images = 0\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(data_dir, image)\n",
    "        try:\n",
    "            # normalizing image data\n",
    "            image_data = (ndimage.imread(image_file).astype(float) -\n",
    "                          PIXEL_DEPTH / 2) / PIXEL_DEPTH\n",
    "            if image_data.shape != (CNN_IN_HEIGHT, CNN_IN_WIDTH, CNN_IN_CH):\n",
    "                raise Exception('Unexpected image shape: %s' %\n",
    "                                str(image_data.shape))\n",
    "            dataset[num_images, :, :] = image_data\n",
    "            num_images = num_images + 1\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image_file, ':', e,\n",
    "                  '-it\\'s ok, skipping.')\n",
    "\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickling the data\n",
    "def maybe_pickle(data_dirs, force=False):\n",
    "    dataset_names = []\n",
    "    for dir in data_dirs:\n",
    "        set_filename = dir + '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename) and not force:\n",
    "            # You may overwrite by setting force=True\n",
    "            print('%s already present - Skipping pickling. ' % set_filename)\n",
    "        else:\n",
    "            print('Pickling %s.' % set_filename)\n",
    "            dataset = load_logo(dir)\n",
    "            try:\n",
    "                with open(set_filename, 'wb') as f:\n",
    "                    pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':', e)\n",
    "    return dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return images with labels with channel = 1\n",
    "def make_arrays(nb_rows, image_width, image_height, image_ch=1):\n",
    "    if nb_rows:\n",
    "        dataset = np.ndarray(\n",
    "            (nb_rows, image_height, image_width, image_ch), dtype=np.float32)\n",
    "        labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "    else:\n",
    "        dataset, labels = None, None\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return validation and test datasets\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "    num_classes = len(pickle_files)\n",
    "    valid_dataset, valid_labels = make_arrays(valid_size, CNN_IN_WIDTH,\n",
    "                                              CNN_IN_HEIGHT, CNN_IN_CH)\n",
    "    train_dataset, train_labels = make_arrays(train_size, CNN_IN_WIDTH,\n",
    "                                              CNN_IN_HEIGHT, CNN_IN_CH)\n",
    "    vsize_per_class = valid_size // num_classes\n",
    "    tsize_per_class = train_size // num_classes\n",
    "\n",
    "    start_v, start_t = 0, 0\n",
    "    end_v, end_t = vsize_per_class, tsize_per_class\n",
    "    end_l = vsize_per_class + tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files):\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                logo_set = pickle.load(f)\n",
    "                np.random.shuffle(logo_set)\n",
    "                if valid_dataset is not None:\n",
    "                    valid_logo = logo_set[:vsize_per_class, :, :, :]\n",
    "                    valid_dataset[start_v:end_v, :, :, :] = valid_logo\n",
    "                    valid_labels[start_v:end_v] = label\n",
    "                    start_v += vsize_per_class\n",
    "                    end_v += vsize_per_class\n",
    "                train_logo = logo_set[vsize_per_class:end_l, :, :, :]\n",
    "                train_dataset[start_t:end_t, :, :, :] = train_logo\n",
    "                train_labels[start_t:end_t] = label\n",
    "                start_t += tsize_per_class\n",
    "                end_t += tsize_per_class\n",
    "        except Exception as e:\n",
    "            print('Unable to process data from', pickle_file, ':', e)\n",
    "            raise\n",
    "    return valid_dataset, valid_labels, train_dataset, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_pickle(train_dataset, train_labels, valid_dataset, valid_labels,\n",
    "                test_dataset, test_labels):\n",
    "    try:\n",
    "        f = open(PICKLE_FILENAME, 'wb')\n",
    "        save = {\n",
    "            'train_dataset': train_dataset,\n",
    "            'train_labels': train_labels,\n",
    "            'valid_dataset': valid_dataset,\n",
    "            'valid_labels': valid_labels,\n",
    "            'test_dataset': test_dataset,\n",
    "            'test_labels': test_labels,\n",
    "        }\n",
    "        pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', PICKLE_FILENAME, ':', e)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# suhuffling datasets\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation, :, :]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Adidas\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Adidas\\train\n",
      "Full dataset tensor: (9216, 64, 64, 3)\n",
      "Mean: -0.0257631\n",
      "Standard deviation: 0.354508\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Apple\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Apple\\train\n",
      "Full dataset tensor: (9252, 64, 64, 3)\n",
      "Mean: 0.124766\n",
      "Standard deviation: 0.301188\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\BMW\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\BMW\\train\n",
      "Full dataset tensor: (4284, 64, 64, 3)\n",
      "Mean: -0.0793146\n",
      "Standard deviation: 0.330199\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Citroen\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Citroen\\train\n",
      "Full dataset tensor: (7560, 64, 64, 3)\n",
      "Mean: 0.105076\n",
      "Standard deviation: 0.363601\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Cocacola\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Cocacola\\train\n",
      "Full dataset tensor: (10080, 64, 64, 3)\n",
      "Mean: -0.0743334\n",
      "Standard deviation: 0.313068\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\DHL\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\DHL\\train\n",
      "Full dataset tensor: (4248, 64, 64, 3)\n",
      "Mean: -0.0361355\n",
      "Standard deviation: 0.327948\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Fedex\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Fedex\\train\n",
      "Full dataset tensor: (4320, 64, 64, 3)\n",
      "Mean: 0.053517\n",
      "Standard deviation: 0.318218\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ferrari\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ferrari\\train\n",
      "Full dataset tensor: (3780, 64, 64, 3)\n",
      "Mean: -0.102485\n",
      "Standard deviation: 0.343803\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ford\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ford\\train\n",
      "Full dataset tensor: (4716, 64, 64, 3)\n",
      "Mean: -0.088548\n",
      "Standard deviation: 0.299354\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Google\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Google\\train\n",
      "Full dataset tensor: (4212, 64, 64, 3)\n",
      "Mean: 0.284856\n",
      "Standard deviation: 0.286434\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\HP\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\HP\\train\n",
      "Full dataset tensor: (3996, 64, 64, 3)\n",
      "Mean: -0.115995\n",
      "Standard deviation: 0.351729\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Heineken\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Heineken\\train\n",
      "Full dataset tensor: (5796, 64, 64, 3)\n",
      "Mean: -0.084567\n",
      "Standard deviation: 0.306983\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Intel\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Intel\\train\n",
      "Full dataset tensor: (4428, 64, 64, 3)\n",
      "Mean: 0.117666\n",
      "Standard deviation: 0.34704\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\McDonalds\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\McDonalds\\train\n",
      "Full dataset tensor: (4464, 64, 64, 3)\n",
      "Mean: -0.0352967\n",
      "Standard deviation: 0.305455\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Mini\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Mini\\train\n",
      "Full dataset tensor: (3780, 64, 64, 3)\n",
      "Mean: -0.0810467\n",
      "Standard deviation: 0.32075\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nbc\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nbc\\train\n",
      "Full dataset tensor: (3780, 64, 64, 3)\n",
      "Mean: -0.00217071\n",
      "Standard deviation: 0.346351\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nike\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nike\\train\n",
      "Full dataset tensor: (5544, 64, 64, 3)\n",
      "Mean: 0.00285606\n",
      "Standard deviation: 0.395357\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Pepsi\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Pepsi\\train\n",
      "Full dataset tensor: (14004, 64, 64, 3)\n",
      "Mean: -0.0576793\n",
      "Standard deviation: 0.345392\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Porsche\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Porsche\\train\n",
      "Full dataset tensor: (4320, 64, 64, 3)\n",
      "Mean: -0.0161197\n",
      "Standard deviation: 0.323975\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Puma\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Puma\\train\n",
      "Full dataset tensor: (4716, 64, 64, 3)\n",
      "Mean: -0.0233063\n",
      "Standard deviation: 0.317861\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\RedBull\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\RedBull\\train\n",
      "Full dataset tensor: (4896, 64, 64, 3)\n",
      "Mean: -0.0708663\n",
      "Standard deviation: 0.333113\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Sprite\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Sprite\\train\n",
      "Full dataset tensor: (10116, 64, 64, 3)\n",
      "Mean: -0.0407024\n",
      "Standard deviation: 0.279859\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Starbucks\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Starbucks\\train\n",
      "Full dataset tensor: (6768, 64, 64, 3)\n",
      "Mean: -0.101481\n",
      "Standard deviation: 0.296122\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Texaco\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Texaco\\train\n",
      "Full dataset tensor: (4392, 64, 64, 3)\n",
      "Mean: 0.066547\n",
      "Standard deviation: 0.338727\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Unicef\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Unicef\\train\n",
      "Full dataset tensor: (6840, 64, 64, 3)\n",
      "Mean: -0.0450909\n",
      "Standard deviation: 0.292251\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Vodafone\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Vodafone\\train\n",
      "Full dataset tensor: (9468, 64, 64, 3)\n",
      "Mean: 0.0483612\n",
      "Standard deviation: 0.343523\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Yahoo\\train.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Yahoo\\train\n",
      "Full dataset tensor: (4140, 64, 64, 3)\n",
      "Mean: 0.262925\n",
      "Standard deviation: 0.315141\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Adidas\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Adidas\\test\n",
      "Full dataset tensor: (3072, 64, 64, 3)\n",
      "Mean: -0.030987\n",
      "Standard deviation: 0.354882\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Apple\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Apple\\test\n",
      "Full dataset tensor: (3084, 64, 64, 3)\n",
      "Mean: 0.119032\n",
      "Standard deviation: 0.303655\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\BMW\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\BMW\\test\n",
      "Full dataset tensor: (1428, 64, 64, 3)\n",
      "Mean: -0.0749364\n",
      "Standard deviation: 0.331164\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Citroen\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Citroen\\test\n",
      "Full dataset tensor: (2520, 64, 64, 3)\n",
      "Mean: 0.103142\n",
      "Standard deviation: 0.366374\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Cocacola\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Cocacola\\test\n",
      "Full dataset tensor: (3360, 64, 64, 3)\n",
      "Mean: -0.0708684\n",
      "Standard deviation: 0.312252\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\DHL\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\DHL\\test\n",
      "Full dataset tensor: (1416, 64, 64, 3)\n",
      "Mean: -0.0333609\n",
      "Standard deviation: 0.328366\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Fedex\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Fedex\\test\n",
      "Full dataset tensor: (1440, 64, 64, 3)\n",
      "Mean: 0.0573336\n",
      "Standard deviation: 0.320902\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ferrari\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ferrari\\test\n",
      "Full dataset tensor: (1260, 64, 64, 3)\n",
      "Mean: -0.0997147\n",
      "Standard deviation: 0.342233\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ford\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Ford\\test\n",
      "Full dataset tensor: (1572, 64, 64, 3)\n",
      "Mean: -0.0910845\n",
      "Standard deviation: 0.300103\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Google\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Google\\test\n",
      "Full dataset tensor: (1404, 64, 64, 3)\n",
      "Mean: 0.283725\n",
      "Standard deviation: 0.285196\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\HP\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\HP\\test\n",
      "Full dataset tensor: (1332, 64, 64, 3)\n",
      "Mean: -0.121315\n",
      "Standard deviation: 0.348596\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Heineken\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Heineken\\test\n",
      "Full dataset tensor: (1932, 64, 64, 3)\n",
      "Mean: -0.0845825\n",
      "Standard deviation: 0.305641\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Intel\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Intel\\test\n",
      "Full dataset tensor: (1476, 64, 64, 3)\n",
      "Mean: 0.113061\n",
      "Standard deviation: 0.34427\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\McDonalds\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\McDonalds\\test\n",
      "Full dataset tensor: (1488, 64, 64, 3)\n",
      "Mean: -0.0311417\n",
      "Standard deviation: 0.304967\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Mini\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Mini\\test\n",
      "Full dataset tensor: (1260, 64, 64, 3)\n",
      "Mean: -0.0771038\n",
      "Standard deviation: 0.324814\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nbc\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nbc\\test\n",
      "Full dataset tensor: (1260, 64, 64, 3)\n",
      "Mean: -0.0060937\n",
      "Standard deviation: 0.344125\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nike\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Nike\\test\n",
      "Full dataset tensor: (1848, 64, 64, 3)\n",
      "Mean: 0.0044352\n",
      "Standard deviation: 0.395516\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Pepsi\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Pepsi\\test\n",
      "Full dataset tensor: (4668, 64, 64, 3)\n",
      "Mean: -0.059603\n",
      "Standard deviation: 0.345065\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Porsche\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Porsche\\test\n",
      "Full dataset tensor: (1440, 64, 64, 3)\n",
      "Mean: -0.017605\n",
      "Standard deviation: 0.319997\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Puma\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Puma\\test\n",
      "Full dataset tensor: (1572, 64, 64, 3)\n",
      "Mean: -0.0252826\n",
      "Standard deviation: 0.321399\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\RedBull\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\RedBull\\test\n",
      "Full dataset tensor: (1632, 64, 64, 3)\n",
      "Mean: -0.0748127\n",
      "Standard deviation: 0.332356\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Sprite\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Sprite\\test\n",
      "Full dataset tensor: (3372, 64, 64, 3)\n",
      "Mean: -0.040584\n",
      "Standard deviation: 0.280623\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Starbucks\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Starbucks\\test\n",
      "Full dataset tensor: (2256, 64, 64, 3)\n",
      "Mean: -0.105025\n",
      "Standard deviation: 0.294071\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Texaco\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Texaco\\test\n",
      "Full dataset tensor: (1464, 64, 64, 3)\n",
      "Mean: 0.0588182\n",
      "Standard deviation: 0.338551\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Unicef\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Unicef\\test\n",
      "Full dataset tensor: (2280, 64, 64, 3)\n",
      "Mean: -0.0299313\n",
      "Standard deviation: 0.296287\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Vodafone\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Vodafone\\test\n",
      "Full dataset tensor: (3156, 64, 64, 3)\n",
      "Mean: 0.0468945\n",
      "Standard deviation: 0.340358\n",
      "Pickling flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Yahoo\\test.pickle.\n",
      "flickr_logos_27_dataset\\flickr_logos_27_dataset_cropped_augmented_images\\Yahoo\\test\n",
      "Full dataset tensor: (1380, 64, 64, 3)\n",
      "Mean: 0.262675\n",
      "Standard deviation: 0.311731\n",
      "Compressed pickle size: 2949844\n"
     ]
    }
   ],
   "source": [
    "# pickle all the datasets \n",
    "def main():\n",
    "    train_dirs = [\n",
    "        os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'train')\n",
    "        for class_name in common.CLASS_NAME\n",
    "    ]\n",
    "    test_dirs = [\n",
    "        os.path.join(CROPPED_AUG_IMAGE_DIR, class_name, 'test')\n",
    "        for class_name in common.CLASS_NAME\n",
    "    ]\n",
    "\n",
    "    train_datasets = maybe_pickle(train_dirs)\n",
    "    test_datasets = maybe_pickle(test_dirs)\n",
    "\n",
    "    valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "        train_datasets, TRAIN_SIZE, VALID_SIZE)\n",
    "    _, _, test_dataset, test_labels = merge_datasets(test_datasets, TEST_SIZE)\n",
    "\n",
    "    train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "    valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)\n",
    "    test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "\n",
    "    save_pickle(train_dataset, train_labels, valid_dataset, valid_labels,\n",
    "                test_dataset, test_labels)\n",
    "    statinfo = os.stat(PICKLE_FILENAME)\n",
    "    print('Compressed pickle size:', statinfo.st_size)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
